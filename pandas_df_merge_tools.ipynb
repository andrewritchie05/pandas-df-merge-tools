{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find max list length within list\n",
    "\n",
    "def find_max_list(list):\n",
    "    list_len = [len(i) for i in list]\n",
    "    return max(list_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns if column name is duplicated \n",
    "# useful after multiple dataframe merges\n",
    "\n",
    "class renamer():\n",
    "            def __init__(self):\n",
    "                  self.d = dict()\n",
    "\n",
    "            def __call__(self, x):\n",
    "                if x not in self.d:\n",
    "                    self.d[x] = 0\n",
    "                    return x\n",
    "                else:\n",
    "                    self.d[x] += 1\n",
    "                    return \"%s_%d\" % (x, self.d[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through each row and remove duplicates (ingnoring NaNs)\n",
    "\n",
    "def dup_dropper(_df):\n",
    "    i = 0 \n",
    "    while i< len(_df):\n",
    "        _df = _df.rename(columns=renamer())\n",
    "        temp = _df.iloc[i]\n",
    "        temp = temp[(~temp.duplicated()) | temp.isna()]\n",
    "        _df.iloc[i] = temp\n",
    "        i+= 1\n",
    "        return _df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes target data spread across multiple columns in a dataframe and condenses it into a smaller number of columns \n",
    "\n",
    "def column_cleanup(item, _df):\n",
    "    item = str(item)\n",
    "\n",
    "    #_df = _df.rename(columns=renamer())\n",
    "    \n",
    "    # search columns for desired (ie cell number)\n",
    "    item_cols = [col for col in _df.columns if str(item) in col]\n",
    "\n",
    "    _df = _df.reset_index(drop=True)\n",
    "    _df = _df.reindex(columns = _df.columns.tolist() + ['{0}_combined'.format(item)])\n",
    "\n",
    "    # we need to split combined items on ',' but some of the original items contain ',' which we wish to keep inplace\n",
    "    # we will replace the original ',' with '&&' for now. This can be returned to original format later if desired.\n",
    "    for col in item_cols:\n",
    "        _df['{0}_combined'.format(item)] =  _df['{0}_combined'.format(item)].astype(str) + ','+ _df[col].astype(str).replace(',','&&')\n",
    "        _df['{0}_combined'.format(item)] = _df['{0}_combined'.format(item)].replace('nan,', '')\n",
    "        _df['{0}_combined'.format(item)] = _df['{0}_combined'.format(item)].replace('nan', '')  \n",
    "\n",
    "    combined_array = np.array(_df['{0}_combined'.format(item)])\n",
    "\n",
    "    idx = 0\n",
    "    while idx < len(combined_array):\n",
    "        combined_array[idx] = combined_array[idx].replace('nan,', '').replace('nan', '')\n",
    "        combined_array[idx] = combined_array[idx].split(',')\n",
    "        idx +=1\n",
    "\n",
    "    _df['{0}_combined'.format(item)] = combined_array\n",
    "\n",
    "    comb_list = np.array(_df['{0}_combined'.format(item)])\n",
    "\n",
    "    clean_list = []\n",
    "    for i in comb_list:\n",
    "        temp_list = []\n",
    "        for j in i:\n",
    "            if j not in temp_list:\n",
    "                if j != '':\n",
    "                    temp_list.append(j)\n",
    "                    #print(temp_list)\n",
    "        clean_list.append(temp_list)\n",
    "\n",
    "    num_items = find_max_list(clean_list)\n",
    "\n",
    "    cell = []\n",
    "    for i in range(0, (num_items)):\n",
    "        cell.append(np.array([]))\n",
    "\n",
    "    i = 0\n",
    "    while i < num_items:\n",
    "        j = 0\n",
    "        temp_array = np.array([])\n",
    "        while j < len(clean_list):\n",
    "            try:\n",
    "                temp_array = np.append(temp_array, clean_list[j][i])\n",
    "                j += 1\n",
    "            except:\n",
    "                temp_array = np.append(temp_array, '')\n",
    "                j += 1\n",
    "        cell[i] = temp_array\n",
    "        i += 1\n",
    "\n",
    "    # drop the original columns, then replace with the combined ones\n",
    "\n",
    "    _df = _df.drop(item_cols, axis=1)\n",
    "    _df = _df.drop('{0}_combined'.format(item), axis =1)\n",
    "\n",
    "    for i in range(0, len(cell)): \n",
    "        _df['{0}_{1}_1'.format(item, (i+1))] = cell[i]\n",
    "        # return the '&&' to ',' as mentioned earlier\n",
    "        _df['{0}_{1}_1'.format(item, (i+1))] = _df['{0}_{1}_1'.format(item, (i+1))].replace('&&',',')\n",
    "\n",
    "    # get rid of any remaining null columns\n",
    "    _df = _df.dropna(axis=1, how='all')\n",
    "\n",
    "    return _df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When using the dup_dropper, values are kept the first time they appear.\n",
    "# For that reason, merge dfs in decreasing order of our confidence regarding their data\n",
    "\n",
    "# Load the dataframes and merge them\n",
    "\n",
    "#df_1 = pd.read_csv('path/*.csv', header=0)\n",
    "#df_2 = pd.read_csv('path/*.csv', header=0)\n",
    "#df_3 = pd.read_csv('path/*.csv', header=0)\n",
    "\n",
    "#df = pd.merge(df_1, \n",
    "#              df_2, \n",
    "#              left_on=['fname', 'lname'],right_on=['fname','lname'], how='left')\n",
    "#df = pd.merge(df, \n",
    "#              df_3, \n",
    "#              left_on=['fname', 'lname'],right_on=['fname','lname'], how='left')\n",
    "\n",
    "#df = dup_dropper(df)\n",
    "#df = df.dropna(axis=1, how='all')\n",
    "#df = df.reset_index(drop=True)\n",
    "\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#columns_list = df.columns.tolist()\n",
    "#columns_list.sort()\n",
    "#print(columns_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# currently have to create list manually...\n",
    "# can write a function to avoid doing this manually every time, come back to this later\n",
    "# idea:\n",
    "#  -> list append col for col contains _x or _y\n",
    "# -> strip the _x/_y\n",
    "#  -> create new list\n",
    "#  -> loop through stripped list appending new list if item in stripped last has not yet been appended\n",
    "#  \n",
    "#  potential issue: above method will likely cause problems if we have very similar column names,\n",
    "#  that represent different data\n",
    "\n",
    "#to_tidy = [ ] # list of columns to be cleaned goes here\n",
    "\n",
    "#for colz in to_tidy:\n",
    "#    #print(colz) # for debugging\n",
    "#    df = column_cleanup(colz, df)\n",
    "    \n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv('path/dataframe.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
